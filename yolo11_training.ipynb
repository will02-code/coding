{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wild deserts image classification\n",
    "Training is done in [Google Colab](https://colab.research.google.com/drive/1SOflnQu87P5v9klSefdetHO2b85fqTIR?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import shutil\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort images into day/night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the source directories for day and night images\n",
    "image_dir_training_day = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\day_night\\\\day\\\\train\"\n",
    "image_dir_test_day = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\day_night\\\\day\\\\test\"\n",
    "image_dir_training_night = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\day_night\\\\night\\\\train\"\n",
    "image_dir_test_night = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\day_night\\\\night\\\\test\"\n",
    "\n",
    "def calculate_brightness_and_hue(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    brightness = hsv_image[:, :, 2].mean()  # V channel represents brightness\n",
    "    hue = hsv_image[:, :, 0].mean()  # H channel represents hue\n",
    "    return brightness, hue\n",
    "\n",
    "def get_brightness_and_hue(directory):\n",
    "    brightness_values = []\n",
    "    hue_values = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".JPG\") or filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            brightness, hue = calculate_brightness_and_hue(image_path)\n",
    "            brightness_values.append(brightness)\n",
    "            hue_values.append(hue)\n",
    "    return brightness_values, hue_values\n",
    "\n",
    "# Get brightness and hue values for each directory\n",
    "training_day_brightness, training_day_hue = get_brightness_and_hue(image_dir_training_day)\n",
    "training_night_brightness, training_night_hue = get_brightness_and_hue(image_dir_training_night)\n",
    "test_day_brightness, test_day_hue = get_brightness_and_hue(image_dir_test_day)\n",
    "test_night_brightness, test_night_hue = get_brightness_and_hue(image_dir_test_night)\n",
    "\n",
    "# Plot the brightness and hue values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(training_day_brightness, training_day_hue, color='blue', label='Training Day')\n",
    "plt.scatter(training_night_brightness, training_night_hue, color='red', label='Training Night')\n",
    "plt.xlabel('Brightness')\n",
    "plt.ylabel('Hue')\n",
    "plt.title('Training Images')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_day_brightness, [0]*len(test_day_brightness), color='blue', label='Test Day')\n",
    "plt.scatter(test_night_brightness, [0]*len(test_night_brightness), color='red', label='Test Night')\n",
    "plt.xlabel('Brightness')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Test Images')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual classification of datasets\n",
    "\n",
    "This is with ALL LABELS. It needs reclassifying as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# Define the source directory and the target directories for day and night images\n",
    "image_source_directory = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_no_split\\\\14_classes_b_plus_empty\\\\images\"\n",
    "label_source_directory = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_no_split\\\\14_classes_b_plus_empty\\\\labels\"\n",
    "\n",
    "day_directory_images = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_day\\\\images\"\n",
    "day_directory_labels = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_day\\\\labels\"\n",
    "\n",
    "night_directory_images = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_night\\\\images\"\n",
    "night_directory_labels = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_night\\\\labels\"\n",
    "\n",
    "# Create the target directories if they do not exist\n",
    "os.makedirs(day_directory_images, exist_ok=True)\n",
    "os.makedirs(day_directory_labels, exist_ok=True)\n",
    "os.makedirs(night_directory_images, exist_ok=True)\n",
    "os.makedirs(night_directory_labels, exist_ok=True)\n",
    "\n",
    "def classify_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    brightness = hsv_image[:, :, 2].mean()  # V channel represents brightness\n",
    "    hue = hsv_image[:, :, 0].mean()  # H channel represents hue\n",
    "    # Adjust the thresholds as needed\n",
    "    if hue > 10:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# Classify and copy images and labels\n",
    "for filename in os.listdir(image_source_directory):\n",
    "    if filename.endswith(\".JPG\") or filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(image_source_directory, filename)\n",
    "        label_path = os.path.join(label_source_directory, filename.replace(\".JPG\", \".txt\").replace(\".jpg\", \".txt\"))\n",
    "        print(f\"Classifying {image_path}\")\n",
    "        classification = classify_image(image_path)\n",
    "        if classification == 'day':\n",
    "            shutil.copy(image_path, os.path.join(day_directory_images, filename))\n",
    "            shutil.copy(label_path, os.path.join(day_directory_labels, os.path.basename(label_path)))\n",
    "        else:\n",
    "            shutil.copy(image_path, os.path.join(night_directory_images, filename))\n",
    "            shutil.copy(label_path, os.path.join(night_directory_labels, os.path.basename(label_path)))\n",
    "\n",
    "print(\"Classification and copying completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(os.makedirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify labels\n",
    "- This uses some basic text editing to replace values that are being reclassified\n",
    "- Faster than reclassifying using X-Anylabel\n",
    "- I also split images into new test/train/val sets after reclassifying.\n",
    "    - I use iterative_train_test_split from Scikit-multilearn to perform stratified classification\n",
    "        - Need to stratify because of the imbalanced dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reclassify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in glob('C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\training\\\\model_training_day\\\\labels\\\\*.txt'):\n",
    "    print(f'{file_path}')\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        modified_lines = []\n",
    "        for line in lines:\n",
    "            to_remove = re.match(r'^(0 .*\\n|3 .*\\n|4 .*\\n|7 .*\\n|9 .*\\n|10 .*\\n|13 .*\\n|15 .*\\n)', line)\n",
    "            kangaroo = re.match(r'^(14 |12 |8 |5 )', line)\n",
    "            rabbit = re.match(r'^(11 )', line)\n",
    "            dingo = re.match(r'^(2 )', line)\n",
    "            fox = re.match(r'^(6 )', line)\n",
    "            if to_remove:\n",
    "                continue  # Skip appending this line\n",
    "            elif kangaroo:\n",
    "                modified_line = re.sub(r'^(14 |12 |8 |5 )', '0 ', line)\n",
    "            elif rabbit:\n",
    "                modified_line = re.sub(r'^(11 )', \"2 \", line)\n",
    "            elif dingo:\n",
    "                modified_line = re.sub(r'^(2 )', \"3 \", line)  \n",
    "            elif fox:\n",
    "                modified_line = re.sub(r'^(6 )', \"4 \", line)  \n",
    "            else:\n",
    "                modified_line = line  \n",
    "            \n",
    "            modified_lines.append(modified_line)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(modified_lines)\n",
    "        print(f'File written to: {file_path}')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is if you want to do validation in digikam or R later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the reclassified images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block actually just extracts the data from the YOLO labels and puts it into two numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your YOLO .txt annotations\n",
    "annotations_path = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\feedback_loop\\\\v1_day_160125\\\\labels\\\\*.txt\"\n",
    "\n",
    "# List all .txt files\n",
    "txt_files = glob(annotations_path)\n",
    "\n",
    "X = []  # Will store image paths or anything representing the \"features\"\n",
    "y = []  # Will store the multi-label vectors of shape (16,)\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    # Construct the corresponding image path\n",
    "    # (assuming .jpg files, adjust if your images are .png, etc.)\n",
    "    img_file = txt_file.replace(\".txt\", \".JPG\")\n",
    "    img_file = img_file.replace(\"labels\", \"images\")\n",
    "    # Initialize a 4-dimensional zero vector for the labels !!! MAKE SURE TO CHANGE IF YOU HAVE MORE CLASSES !!!\n",
    "    labels = np.zeros(5, dtype=int)\n",
    "    print(txt_file)\n",
    "    # Read the YOLO annotation file\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            items = line.strip().split()\n",
    "            if len(items) >= 5:\n",
    "                class_id = int(items[0])\n",
    "                # Mark that class_id as present\n",
    "                labels[class_id] = 1\n",
    "\n",
    "    # Append to X and y\n",
    "    X.append(img_file)     # or store actual image data if needed\n",
    "    y.append(labels)\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape(-1, 1)\n",
    "y = np.array(y)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is the actual splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.2 #10% of the data will be used for test\n",
    "\n",
    "# Perform the iterative train/test split\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_size)\n",
    "X_test = X_test.ravel()  \n",
    "X_train = X_train.ravel()\n",
    "print(\"After first split:\")\n",
    "print(\"  train:\", X_train.shape, y_train.shape)\n",
    "\n",
    "print(\"  test:     \", X_test.shape,    y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate image split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_classes(y_data):\n",
    "    \"\"\" Sum over axis=0 to get how many samples contain each class. \"\"\"\n",
    "    return y_data.sum(axis=0)\n",
    "\n",
    "def print_class_stats(name, y_data):\n",
    "    counts = count_classes(y_data)\n",
    "    print(f\"{name} - counts per class: {counts}\")\n",
    "    print(f\"{name} - total samples: {len(y_data)}\\n\")\n",
    "\n",
    "print_class_stats(\"TRAIN\", y_train)\n",
    "print_class_stats(\"TEST\",  y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the files into their actual folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "#Change these to your directories\n",
    "labels_dir = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\feedback_loop\\\\v1_day_160125\\\\labels\"\n",
    "images_dir = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\feedback_loop\\\\v1_day_160125\\\\images\"\n",
    "# Create \"labels\" and \"images\" folders in each directory\n",
    "for directory in [labels_dir, images_dir]:\n",
    "    os.makedirs(os.path.join(directory, \"val\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(directory, \"train\"), exist_ok=True)\n",
    "    #os.makedirs(os.path.join(directory, \"val\"), exist_ok=True)\n",
    "# Copy test images and labels. Note that this leaves the files in the original directories too\n",
    "for img_path in tqdm(X_test, desc=\"Copying val data\"):\n",
    "    \n",
    "    txt_path = img_path.replace(\".JPG\", \".txt\")\n",
    "    txt_path = txt_path.replace(\"images\", \"labels\")\n",
    "\n",
    "    shutil.copy(img_path, os.path.join(images_dir, \"val\"))\n",
    "    shutil.copy(txt_path, os.path.join(labels_dir, \"val\"))\n",
    "# Copy training images and labels\n",
    "for img_path in tqdm(X_train, desc=\"Copying training data\"):\n",
    "    txt_path = img_path.replace(\".JPG\", \".txt\")  # or .png, whichever you have\n",
    "    txt_path = txt_path.replace(\"images\", \"labels\")\n",
    "    shutil.copy(img_path, os.path.join(images_dir, \"train\"))\n",
    "    shutil.copy(txt_path, os.path.join(labels_dir, \"train\"))\n",
    "\n",
    "# Copy validation images and labels\n",
    "'''for img_path in tqdm(X_val, desc=\"Copying validation data\"):\n",
    "    txt_path = img_path.replace(\".JPG\", \".txt\")  # or .png, whichever you have\n",
    "    txt_path = txt_path.replace(\"images\", \"labels\")\n",
    "\n",
    "    shutil.copy(img_path, os.path.join(images_dir, \"val\"))\n",
    "    shutil.copy(txt_path, os.path.join(labels_dir, \"val\"))'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables/filepaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained model validation/prediction\n",
    "The model needs to be trained on Colab prior to this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This block is an old training workflow but I have kept it here for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "all_detections = []\n",
    "for folder in os.listdir(f\"{validation_root_directory}/all_images/\"):\n",
    "    print(folder)\n",
    "    directory = f\"{validation_root_directory}/all_images/{folder}/\"\n",
    "    \n",
    "    for counter, image in enumerate(os.listdir(directory), start=1):\n",
    "        name, ext = os.path.splitext(image)\n",
    "        print(f\"{counter}/{len(os.listdir(directory))}\")\n",
    "        \n",
    "        if ext == '.JPG':  \n",
    "            \n",
    "            predictions = model.predict(\n",
    "                source=os.path.join(directory, image),\n",
    "                save=True,\n",
    "                save_txt=True,\n",
    "                save_conf=False,\n",
    "                imgsz=640,\n",
    "                conf=0.1,\n",
    "                iou=0.5,\n",
    "                augment=True,\n",
    "                project=f\"{validation_root_directory}/output3/labels_images/predict\",\n",
    "                name = \"test\"\n",
    "            )\n",
    "            os.makedirs(f\"{validation_root_directory}/output3/labels_images/predict/images\", exist_ok=True)\n",
    "            shutil.copy(os.path.join(directory, image), f\"{validation_root_directory}/output3/labels_images/predict/images/{name}.jpg\")\n",
    "            if predictions[0]:\n",
    "                species = model.names[int(predictions[0].boxes.cls[0])]\n",
    "                conf = round(float(predictions[0].boxes.conf[0]), 3)\n",
    "                path = predictions[0].path\n",
    "                print(path)\n",
    "                bbox = predictions[0].boxes.xywh.tolist()\n",
    "                df = pd.DataFrame({'path': path, 'species': species, 'confidence': conf, 'bbox': bbox, })\n",
    "                all_detections.append(df)\n",
    "                newpath = f\"{validation_root_directory}/output3/{species}\"\n",
    "            else:\n",
    "                print(\"No detections were made.\")\n",
    "                newpath = f\"{validation_root_directory}/output3/empty\"\n",
    "            \n",
    "            os.makedirs(newpath, exist_ok=True)\n",
    "            predictions[0].save(f\"{newpath}/{name}_{conf if predictions[0] else ''}.jpg\")\n",
    "            \n",
    "            os.makedirs(all_images_path, exist_ok=True)\n",
    "            predictions[0].save(f\"{all_images_path}/{name}_{conf if predictions[0] else ''}_{species if predictions[0] else 'empty'}.jpg\")\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "if all_detections:\n",
    "    final_df = pd.concat(all_detections)\n",
    "    final_df.to_csv(f\"{validation_root_directory}/output3/detections_{timestamp}.csv\", index=False)\n",
    "else:\n",
    "    print(\"No detections were made.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New training block\n",
    "Note that this is all better using a gpu. Probably 10x faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to split into day/night images for the day/night models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# Define the source directory and the target directories for day and night images\n",
    "image_source_directory = \"D:\\\\Wild deserts photos\\\\Reconyx\\\\BeyondTheFence\\\\PCAM14\"\n",
    "\n",
    "day_directory_images = \"D:\\\\Wild deserts photos\\\\Reconyx\\\\BeyondTheFence\\\\PCAM14\\\\day\"\n",
    "\n",
    "night_directory_images = \"D:\\\\Wild deserts photos\\\\Reconyx\\\\BeyondTheFence\\\\PCAM14\\\\night\"\n",
    "\n",
    "# Create the target directories if they do not exist\n",
    "os.makedirs(day_directory_images, exist_ok=True)\n",
    "os.makedirs(night_directory_images, exist_ok=True)\n",
    "\n",
    "def classify_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    brightness = hsv_image[:, :, 2].mean()  # V channel represents brightness\n",
    "    hue = hsv_image[:, :, 0].mean()  # H channel represents hue\n",
    "    # Adjust the thresholds as needed\n",
    "    if hue > 10:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# Classify and copy images\n",
    "for filename in os.listdir(image_source_directory):\n",
    "    if filename.endswith(\".JPG\") or filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(image_source_directory, filename)\n",
    "        print(image_path)\n",
    "        classification = classify_image(image_path)\n",
    "        if classification == 'day':\n",
    "            shutil.copy(image_path, os.path.join(day_directory_images, filename))\n",
    "        else:\n",
    "            shutil.copy(image_path, os.path.join(night_directory_images, filename))\n",
    "\n",
    "print(\"Classification and copying completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_root_directory = \"D:\\\\Wild deserts photos\\\\Reconyx\\\\BeyondTheFence\\\\PCAM14\\\\day\"\n",
    "model = YOLO(\"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\feedback_loop\\\\v1_day_160125\\\\output\\\\content\\\\runs\\\\detect\\\\train2\\\\weights\\\\best.pt\")\n",
    "directory = f\"{validation_root_directory}\"\n",
    "\n",
    "\n",
    "predictions = model.predict(\n",
    "    source=os.path.join(directory),\n",
    "    save=False, # I don't save anything here because I want to sort into folders\n",
    "    save_txt=False,\n",
    "    save_conf=False,\n",
    "    imgsz=640,\n",
    "    conf=0.1,\n",
    "    iou=0.5,\n",
    "    show=False, \n",
    "    stream = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this block if stream = TRUE (for large datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detections = []\n",
    "model_name = \"model_training_night_feedback_loop\"\n",
    "annotated_dir_val = \"D:\\\\Wild deserts photos\\\\all_annotated_images\\\\day\"\n",
    "for prediction in predictions:\n",
    "    if prediction.boxes:  # Check if there are any boxes in the prediction\n",
    "        species = model.names[int(prediction.boxes.cls[0])]\n",
    "        conf = round(float(prediction.boxes.conf[0]), 3)\n",
    "        path = prediction.path\n",
    "        name = os.path.splitext(os.path.basename(prediction.path))[0]\n",
    "        bbox = prediction.boxes.xywh.tolist()\n",
    "        labels_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/labels\"\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        labels_path = f\"{labels_dir}/{name}.txt\"\n",
    "        prediction.save_txt(labels_path)\n",
    "    else:\n",
    "        species = \"none\"\n",
    "        conf = \"none\"\n",
    "        path = prediction.path\n",
    "        name = os.path.splitext(os.path.basename(prediction.path))[0]\n",
    "        bbox = \"none\"\n",
    "        labels_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/labels\"\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        labels_path = f\"{labels_dir}/{name}.txt\"\n",
    "        with open(labels_path, 'w') as f:\n",
    "            f.write('')\n",
    "        print(f\"No detections for prediction {name}\")\n",
    "    #CHANGE THIS PATH FOR VALIDATION\n",
    "    newpath = f\"{annotated_dir_val}/{species}\"\n",
    "    os.makedirs(newpath, exist_ok=True)\n",
    "    prediction.save(f\"{newpath}/{name}_{conf}.jpg\")\n",
    "\n",
    "    images_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/images\"\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    shutil.copy(path, images_dir)\n",
    "    path_original = f\"{images_dir}/{name}.JPG\"\n",
    "\n",
    "    annotated_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/annotated\"\n",
    "    os.makedirs(annotated_dir, exist_ok=True)\n",
    "    path_annotated = f\"{annotated_dir}/{name}_{conf}.JPG\"\n",
    "    prediction.save(path_annotated)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'path_original': [path_original],\n",
    "        'species': [species],\n",
    "        'confidence': [conf],\n",
    "        'bbox': [bbox],\n",
    "        'path_annotated': [path_annotated],\n",
    "        'label_path': [labels_path]\n",
    "    })\n",
    "\n",
    "    all_detections.append(df)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "if all_detections:\n",
    "    final_df = pd.concat(all_detections, ignore_index=True)\n",
    "    final_df.to_csv(f\"{validation_root_directory}/{model_name}/detections_{timestamp}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detections = []\n",
    "model_name = \"model_training_night_feedback_loop\"  \n",
    "for i in range(len(predictions)):\n",
    "    #if detections\n",
    "    if predictions[i].boxes:  # Check if there are any boxes in the prediction\n",
    "        species = model.names[int(predictions[i].boxes.cls[0])]\n",
    "        conf = round(float(predictions[i].boxes.conf[0]), 3)\n",
    "        path = predictions[i].path\n",
    "        # Use the correct index i instead of 1\n",
    "        name = os.path.splitext(os.path.basename(predictions[i].path))[0]\n",
    "        bbox = predictions[i].boxes.xywh.tolist()\n",
    "        # 5) Save the label file in the \"labels\" folder\n",
    "        labels_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/labels\"\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        labels_path = f\"{labels_dir}/{name}.txt\"\n",
    "        predictions[i].save_txt(labels_path)\n",
    "    #if no detections\n",
    "    else:\n",
    "        species = \"none\"\n",
    "        conf = \"none\"\n",
    "        path = predictions[i].path\n",
    "        name = os.path.splitext(os.path.basename(predictions[i].path))[0]\n",
    "        bbox = \"none\"\n",
    "        labels_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/labels\"\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        labels_path = f\"{labels_dir}/{name}.txt\"\n",
    "        with open(labels_path, 'w') as f:\n",
    "            f.write('')\n",
    "        print(f\"No detections for prediction {i}\")\n",
    "        \n",
    "    # 1) Create a folder for this species\n",
    "    newpath = f\"{validation_root_directory}/{model_name}/{species}\"\n",
    "    os.makedirs(newpath, exist_ok=True)\n",
    "\n",
    "    # 2) Save the annotated image to the species folder\n",
    "    predictions[i].save(f\"{newpath}/{name}.jpg\")\n",
    "\n",
    "    # 3) Save the original image in the \"images\" folder\n",
    "    images_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/images\"\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    shutil.copy(path, images_dir)\n",
    "    path_original = f\"{images_dir}/{name}.JPG\"\n",
    "\n",
    "    # 4) Save the annotated image in the \"annotated\" folder\n",
    "    annotated_dir = f\"{validation_root_directory}/{model_name}/labels_images/predict/annotated\"\n",
    "    os.makedirs(annotated_dir, exist_ok=True)\n",
    "    path_annotated = f\"{annotated_dir}/{name}_{conf}.JPG\"\n",
    "    predictions[i].save(path_annotated)\n",
    "\n",
    "\n",
    "\n",
    "    # 5) Build a DataFrame row (no classification check here)\n",
    "    df = pd.DataFrame({\n",
    "        'path_original': [path_original],\n",
    "        'species': [species],\n",
    "        'confidence': [conf],\n",
    "        'bbox': [bbox],\n",
    "        'path_annotated': [path_annotated],\n",
    "        'label_path': [labels_path]\n",
    "    })\n",
    "\n",
    "    # 6) Append this to all_detections\n",
    "    all_detections.append(df)\n",
    "    \n",
    "\n",
    "\n",
    "# Finally, save all detections to a CSV\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "if all_detections:\n",
    "    final_df = pd.concat(all_detections, ignore_index=True)\n",
    "    final_df.to_csv(f\"{validation_root_directory}/{model_name}/detections_{timestamp}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(all_predictions)):\n",
    "    if all_predictions[i].boxes:  # Check if there are any boxes in the prediction\n",
    "        species = model.names[int(all_predictions[i].boxes.cls[0])]\n",
    "        conf = round(float(all_predictions[i].boxes.conf[0]), 3)\n",
    "        path = all_predictions[i].path\n",
    "        name = os.path.splitext(os.path.basename(all_predictions[i].path))[0]\n",
    "        bbox = all_predictions[i].boxes.xywh.tolist()\n",
    "        # save the label file to the labels folder\n",
    "        labels_path = f\"{validation_root_directory}/output3/labels_images/predict/labels/{name}.txt\"\n",
    "        all_predictions[i].save_txt(labels_path)\n",
    "\n",
    "    else:\n",
    "        species = \"none\"\n",
    "        conf = \"none\"\n",
    "        path = all_predictions[i].path\n",
    "        name = os.path.splitext(os.path.basename(all_predictions[i].path))[0]\n",
    "        bbox = \"none\"\n",
    "        labels_dir = f\"{validation_root_directory}/output3/labels_images/predict/labels\"\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        labels_path = f\"{labels_dir}/{name}.txt\"\n",
    "        with open(labels_path, 'w') as f:\n",
    "            f.write('')\n",
    "        print(f\"No detections for prediction {i}\")\n",
    "    \n",
    "    # save the annotated image to the species folder\n",
    "    newpath = f\"{validation_root_directory}/output3/{species}\"  \n",
    "    os.makedirs(newpath, exist_ok=True)\n",
    "    all_predictions[i].save(f\"{newpath}/{name}.jpg\")\n",
    "        \n",
    "    # save the original image to the images folder\n",
    "    os.makedirs(f\"{validation_root_directory}/output3/labels_images/predict/images\", exist_ok=True)\n",
    "    shutil.copy(path, f\"{validation_root_directory}/output3/labels_images/predict/images\")\n",
    "    path_original = f\"{validation_root_directory}/output3/labels_images/predict/images/{name}.JPG\"\n",
    "        \n",
    "    # save the annotated image to the annotated folder\n",
    "    path_annotated = f\"{validation_root_directory}/output3/labels_images/predict/annotated/{name}.JPG\"\n",
    "    os.makedirs(f\"{validation_root_directory}/output3/labels_images/predict/annotated\", exist_ok=True)\n",
    "    all_predictions[i].save(f\"{validation_root_directory}/output3/labels_images/predict/annotated/{name}.JPG\")\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Display the annotated image in a pop-up window with smaller size\n",
    "    img = cv2.imread(path_annotated)\n",
    "    img_resized = cv2.resize(img, (800, 600))  # Resize the image to 800x600\n",
    "    cv2.imshow(f\"Species: {species}, Confidence: {conf}\", img_resized)\n",
    "\n",
    "    cv2.moveWindow(f\"Species: {species}, Confidence: {conf}\", 0, 0)  # Move the window to the top left corner\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Prompt user for input\n",
    "    result = input(\"Is the detection correct? (y/n): \").strip().lower()\n",
    "    \n",
    "    # save the data to a dataframe\n",
    "    df = pd.DataFrame({'path_original': [path_original], \n",
    "                        'species': [species], \n",
    "                        'confidence': [conf], \n",
    "                        'bbox': [bbox], \n",
    "                        \"path_annotated\": [path_annotated],\n",
    "                        \"label_path\": [labels_path],\n",
    "                        \"results\": [result]})\n",
    "    \n",
    "    # append the dataframe to the list of all detections\n",
    "    all_detections.append(df)\n",
    "    \n",
    "\n",
    "# Save the results to a CSV file\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "if all_detections:\n",
    "    final_df = pd.concat(all_detections)\n",
    "    final_df.to_csv(f\"{validation_root_directory}/output3/detections_{timestamp}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1].path\n",
    "name = os.path.splitext(os.path.basename(predictions[1].path))[0]\n",
    "name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directories\n",
    "dir2 = \"C:\\\\Users\\\\willo\\\\OneDrive - UNSW\\\\Documents\\\\Work\\\\CES\\\\Wild Deserts\\\\Image classification\\\\feedback_loop\\\\v1_night_16012025\\\\images\\\\val\"\n",
    "# Walk through all subdirectories in the root directory\n",
    "for root, dirs, files in os.walk(\"D:\\\\Wild deserts photos\\\\Reconyx\"):\n",
    "    # Get the list of image files in each subdirectory\n",
    "    images_dir1 = set(os.listdir(root))\n",
    "    images_dir2 = set(os.listdir(dir2))\n",
    "\n",
    "    # Find the intersection of the two sets\n",
    "    shared_images = images_dir1.intersection(images_dir2)\n",
    "\n",
    "    # Delete the shared images from the current subdirectory\n",
    "    for image in shared_images:\n",
    "        print(image)\n",
    "        image_path = os.path.join(root, image)\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "            print(f\"Deleted {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
