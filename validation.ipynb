{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CustomConfusionMatrix:\n",
    "    \"\"\"\n",
    "    Custom confusion matrix that stores all detections (including low conf)\n",
    "    and allows re-computing the confusion matrix at different confidence thresholds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nc, iou_thres=0.45, task=\"detect\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            nc (int): Number of classes (not counting 'background').\n",
    "            iou_thres (float): IoU threshold to decide TPs vs. FPs.\n",
    "            task (str): 'detect' or 'classify'. For multi-class detection, set 'detect'.\n",
    "        \"\"\"\n",
    "        self.task = task\n",
    "        self.nc = nc\n",
    "        self.iou_thres = iou_thres\n",
    "\n",
    "        # Instead of a single matrix, we store the \"match\" info for each image in a list\n",
    "        # Each entry is a dict with:\n",
    "        #   \"gt_classes\": shape (n_gt,)\n",
    "        #   \"det_classes\": shape (n_det,)\n",
    "        #   \"det_confs\": shape (n_det,)\n",
    "        #   \"matches\": shape (m, 3) with columns = (gt_index, det_index, iou)\n",
    "        # This is enough to rebuild confusion matrix for any conf threshold\n",
    "        self.matches_per_image = []\n",
    "\n",
    "    def accumulate_matches(self, detections, gt_bboxes, gt_cls):\n",
    "        \"\"\"\n",
    "        Accumulate all detection-vs-gt matches for a single image, without confidence filtering.\n",
    "\n",
    "        Args:\n",
    "            detections (tensor): shape (n_det, 6 or 7). Format: (x1, y1, x2, y2, conf, class[, angle])\n",
    "            gt_bboxes (tensor): shape (n_gt, 4 or 5). Ground-truth boxes\n",
    "            gt_cls (tensor): shape (n_gt,). Ground-truth classes\n",
    "        \"\"\"\n",
    "        # If no GT, store detections anyway (they become potential false positives for any conf>0)\n",
    "        if gt_cls.shape[0] == 0:\n",
    "            if detections is not None and len(detections) > 0:\n",
    "                # We store them with no matches\n",
    "                self.matches_per_image.append({\n",
    "                    \"gt_classes\": torch.zeros((0,), dtype=torch.int),\n",
    "                    \"det_classes\": detections[:, 5].int().cpu() if len(detections.shape) > 1 else [],\n",
    "                    \"det_confs\": detections[:, 4].cpu() if len(detections.shape) > 1 else [],\n",
    "                    \"matches\": np.zeros((0, 3))\n",
    "                })\n",
    "            return\n",
    "\n",
    "        # If no detections\n",
    "        if detections is None or len(detections) == 0:\n",
    "            self.matches_per_image.append({\n",
    "                \"gt_classes\": gt_cls.int().cpu(),\n",
    "                \"det_classes\": torch.zeros((0,), dtype=torch.int),\n",
    "                \"det_confs\": torch.zeros((0,)),\n",
    "                \"matches\": np.zeros((0, 3))\n",
    "            })\n",
    "            return\n",
    "\n",
    "        # Otherwise, we do IoU matching\n",
    "        det_confs = detections[:, 4]\n",
    "        det_classes = detections[:, 5].int()\n",
    "        is_obb = (detections.shape[1] == 7 and gt_bboxes.shape[1] == 5)\n",
    "        # Box iou\n",
    "        if is_obb:\n",
    "            from math import sqrt\n",
    "            # Suppose you have a suitable OBB IoU function: batch_probiou\n",
    "            iou = batch_probiou(gt_bboxes, torch.cat([detections[:, :4], detections[:, -1:]], dim=-1))\n",
    "        else:\n",
    "            iou = box_iou(gt_bboxes, detections[:, :4])\n",
    "\n",
    "        # Let's find all iou > self.iou_thres\n",
    "        x = torch.where(iou > self.iou_thres)\n",
    "        if x[0].shape[0]:\n",
    "            # Each matched pair is (gt_idx, det_idx, iou_val)\n",
    "            temp_matches = torch.cat([torch.stack(x, 1), iou[x[0], x[1]][:, None]], dim=1)\n",
    "            matches = temp_matches.cpu().numpy()\n",
    "\n",
    "            # We apply the same matching logic from YOLO: highest iou gets the match\n",
    "            matches = matches[matches[:, 2].argsort()[::-1]]  # sort by iou descending\n",
    "            # Unique detection indices\n",
    "            _, unique_det_idx = np.unique(matches[:, 1], return_index=True)\n",
    "            matches = matches[unique_det_idx]\n",
    "            # Unique GT\n",
    "            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "            _, unique_gt_idx = np.unique(matches[:, 0], return_index=True)\n",
    "            matches = matches[unique_gt_idx]\n",
    "        else:\n",
    "            matches = np.zeros((0, 3))\n",
    "\n",
    "        # Store results for later\n",
    "        self.matches_per_image.append({\n",
    "            \"gt_classes\": gt_cls.int().cpu(),\n",
    "            \"det_classes\": det_classes.cpu(),\n",
    "            \"det_confs\": det_confs.cpu(),\n",
    "            \"matches\": matches\n",
    "        })\n",
    "\n",
    "    def compute_matrix(self, conf_thres=0.25):\n",
    "        \"\"\"\n",
    "        Given a confidence threshold, compute and return the confusion matrix.\n",
    "\n",
    "        The returned matrix is (nc+1, nc+1) in 'detect' mode:\n",
    "            rows = predicted (including background as last row)\n",
    "            cols = ground-truth (including background as last col)\n",
    "        \"\"\"\n",
    "        # Initialize matrix\n",
    "        if self.task == \"detect\":\n",
    "            matrix = np.zeros((self.nc + 1, self.nc + 1), dtype=np.int32)\n",
    "        else:\n",
    "            matrix = np.zeros((self.nc, self.nc), dtype=np.int32)\n",
    "\n",
    "        for item in self.matches_per_image:\n",
    "            gt_classes = item[\"gt_classes\"].numpy()\n",
    "            det_classes = item[\"det_classes\"].numpy()\n",
    "            det_confs = item[\"det_confs\"].numpy()\n",
    "            matches = item[\"matches\"]  # shape (m,3): [gt_idx, det_idx, iou]\n",
    "\n",
    "            if len(gt_classes) == 0:\n",
    "                # no ground-truth → all detections are false positives\n",
    "                # but only for those with conf >= conf_thres\n",
    "                if len(det_classes) > 0:\n",
    "                    above = det_confs >= conf_thres\n",
    "                    for dc in det_classes[above]:\n",
    "                        if self.task == \"detect\":\n",
    "                            matrix[dc, self.nc] += 1  # predicted class -> background col\n",
    "                        else:\n",
    "                            matrix[dc, 0] += 1\n",
    "                continue\n",
    "\n",
    "            if len(det_classes) == 0:\n",
    "                # no detections → all gt are missed (FN)\n",
    "                for gc in gt_classes:\n",
    "                    if self.task == \"detect\":\n",
    "                        matrix[self.nc, gc] += 1  # background row -> gt class\n",
    "                    else:\n",
    "                        matrix[gc, gc] += 1  # for classification tasks\n",
    "                continue\n",
    "\n",
    "            # We have both GT and detections\n",
    "            # For confusion matrix, filter detections by conf_thres\n",
    "            used_det = np.zeros_like(det_classes, dtype=bool)\n",
    "            # Convert matches to int\n",
    "            matches = matches.astype(int, copy=False)\n",
    "\n",
    "            for gt_idx, det_idx, _ in matches:\n",
    "                # If that detection has conf >= threshold\n",
    "                if det_confs[det_idx] >= conf_thres and not used_det[det_idx]:\n",
    "                    pred_c = det_classes[det_idx]\n",
    "                    true_c = gt_classes[gt_idx]\n",
    "                    if self.task == \"detect\":\n",
    "                        matrix[pred_c, true_c] += 1\n",
    "                    else:\n",
    "                        matrix[pred_c, true_c] += 1\n",
    "                    used_det[det_idx] = True\n",
    "                # If conf < threshold or already used, it won't count as TP\n",
    "\n",
    "            # All ground-truth that did not get matched above → FN\n",
    "            # The matched GT indices are\n",
    "            matched_gt = matches[:, 0]\n",
    "            matched_gt_unique = np.unique(matched_gt)\n",
    "            # We want the GT indices that did not match at all or matched with a detection < conf_thres\n",
    "            unmatched_gt = list(set(range(len(gt_classes))) - set(matched_gt_unique))\n",
    "            # For matched GT, check if the detection used had conf < threshold\n",
    "            for g in matched_gt_unique:\n",
    "                # which detection was used\n",
    "                sub = matches[matches[:, 0] == g]\n",
    "                # g can match multiple detections, but only 1 used if any\n",
    "                used = any(\n",
    "                    (det_confs[d_idx] >= conf_thres and not used_det[d_idx] == False)\n",
    "                    for _, d_idx, __ in sub\n",
    "                )\n",
    "                if not used:\n",
    "                    unmatched_gt.append(g)\n",
    "\n",
    "            for g in unmatched_gt:\n",
    "                gc = gt_classes[g]\n",
    "                if self.task == \"detect\":\n",
    "                    matrix[self.nc, gc] += 1\n",
    "                else:\n",
    "                    # for classification tasks, typically no background row\n",
    "                    # but you can adapt logic\n",
    "                    pass\n",
    "\n",
    "            # Detections that are above conf but not matched → FP\n",
    "            for d_idx, dc in enumerate(det_classes):\n",
    "                if det_confs[d_idx] >= conf_thres and not used_det[d_idx]:\n",
    "                    if self.task == \"detect\":\n",
    "                        matrix[dc, self.nc] += 1\n",
    "                    else:\n",
    "                        # classification tasks, increment matrix[dc, ???]\n",
    "                        pass\n",
    "\n",
    "        return matrix\n",
    "\n",
    "# ---------------- Utility IoU for boxes ---------------\n",
    "\n",
    "def box_iou(box1, box2, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Standard box IoU.\n",
    "    box1 shape: (N,4), box2 shape: (M,4) in xyxy\n",
    "    \"\"\"\n",
    "    (a1, a2), (b1, b2) = box1.float().unsqueeze(1).chunk(2, 2), box2.float().unsqueeze(0).chunk(2, 2)\n",
    "    inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)\n",
    "    return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)\n",
    "\n",
    "def batch_probiou(obb1, obb2, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Example oriented bounding box IoU.\n",
    "    Replace with your actual OBB IoU implementation if desired.\n",
    "    \"\"\"\n",
    "    # For demonstration, fallback to naive IoU on xyxy\n",
    "    # Typically you'd implement the actual formula from the YOLO source.\n",
    "    # Just returning standard box_iou to keep code consistent\n",
    "    return box_iou(obb1[:, :4], obb2[:, :4], eps=eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CustomConfusionMatrix(nc=NUM_CLASSES, iou_thres=0.45, task=\"detect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
